<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Plasticity-based Learning in DNNs | Suyash Bagad</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Plasticity-based Learning in DNNs" />
<meta name="author" content="Personal Webpage" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Plasticity is essential component in many biological neural networks, however many state of the art deep learning methods do not incorporate plasticity. Taking inspiration from the main mechanism of learning in biological brains: synaptic plasticity, carefully tuned by evolution to produce efficient lifelong learning, me along with my friend Uddeshya explored how could plasticity be infused in Deep and Convolutional Neural Networks to enhance the performance in terms of accuracy and memory footprint. We proposed a methodology on how to train such networks and study the effect of plasticity in different settings." />
<meta property="og:description" content="Plasticity is essential component in many biological neural networks, however many state of the art deep learning methods do not incorporate plasticity. Taking inspiration from the main mechanism of learning in biological brains: synaptic plasticity, carefully tuned by evolution to produce efficient lifelong learning, me along with my friend Uddeshya explored how could plasticity be infused in Deep and Convolutional Neural Networks to enhance the performance in terms of accuracy and memory footprint. We proposed a methodology on how to train such networks and study the effect of plasticity in different settings." />
<link rel="canonical" href="http://localhost:4000/homepage/project/2018/11/30/plasticity-based-learning.html" />
<meta property="og:url" content="http://localhost:4000/homepage/project/2018/11/30/plasticity-based-learning.html" />
<meta property="og:site_name" content="Suyash Bagad" />
<meta property="og:image" content="http://localhost:4000/homepage/plasticity_cover.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-11-30T00:00:00+05:30" />
<script type="application/ld+json">
{"description":"Plasticity is essential component in many biological neural networks, however many state of the art deep learning methods do not incorporate plasticity. Taking inspiration from the main mechanism of learning in biological brains: synaptic plasticity, carefully tuned by evolution to produce efficient lifelong learning, me along with my friend Uddeshya explored how could plasticity be infused in Deep and Convolutional Neural Networks to enhance the performance in terms of accuracy and memory footprint. We proposed a methodology on how to train such networks and study the effect of plasticity in different settings.","@type":"BlogPosting","url":"http://localhost:4000/homepage/project/2018/11/30/plasticity-based-learning.html","headline":"Plasticity-based Learning in DNNs","dateModified":"2018-11-30T00:00:00+05:30","datePublished":"2018-11-30T00:00:00+05:30","image":"http://localhost:4000/homepage/plasticity_cover.png","author":{"@type":"Person","name":"Personal Webpage"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/homepage/project/2018/11/30/plasticity-based-learning.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/homepage/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/homepage/feed.xml" title="Suyash Bagad" /><link rel="apple-touch-icon" sizes="180x180" href="/homepage/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/homepage/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/homepage/favicon-16x16.png">
  <link rel="manifest" href="/homepage/site.webmanifest">
  <link rel="mask-icon" href="/homepage/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  
  <!-- <link href="https://fonts.googleapis.com/css?family=Roboto+Mono|Roboto+Slab:300|Roboto:500" rel="stylesheet"> -->
  <link href="https://fonts.googleapis.com/css?family=Montserrat:300|Raleway&display=swap" rel="stylesheet">

  <!-- KaTeX installation -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
  <!-- <link rel="stylesheet" href="/assets/css/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous"> -->

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
  <!-- <script defer src="/assets/js/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script> -->

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
      onload="renderMathInElement(document.body);"></script>

</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/homepage/">Suyash Bagad</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            <a class="page-link" href="/homepage/404.html"></a>
          
            <a class="page-link" href="/homepage/"></a>
          
            <a class="page-link" href="/homepage/assets/css/style.css"></a>
          
            <a class="page-link" href="/homepage/feed.xml"></a>
          
            <a class="page-link" href="/homepage/projects/">Projects</a>
          
            <a class="page-link" href="/homepage/education/">Education</a>
          
            <a class="page-link" href="/homepage/awards/">Awards</a>
          
            <a class="page-link" href="/homepage/blog/">Blog</a>
          
            <a class="page-link" href="/homepage/personal/">Personal</a>
          
            <a class="page-link" href="/homepage/cv/">CV</a>
          
          <!--<a class="page-link" href="/homepage/awards/">Awards</a><a class="page-link" href="/homepage/blog/">Blog</a><a class="page-link" href="/homepage/cv/">CV</a><a class="page-link" href="/homepage/education/">Education</a><a class="page-link" href="/homepage/personal/">Personal</a><a class="page-link" href="/homepage/projects/">Projects</a>-->
        </div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="project h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="project-header">
    <h1 class="project-title p-name" itemprop="name headline">Plasticity-based Learning in DNNs</h1>
    <p class="project-meta">
      <time class="dt-published" datetime="2018-11-30T00:00:00+05:30" itemprop="datePublished">Nov 30, 2018
      </time></p>
  </header>

  <div class="project-image" itemprop="projImage"><!--  -->


    <figure>
        <img src="/homepage/assets/images/Plasticity-based Learning in DNNs/plasticity_cover.png"  />
        <figcaption></figcaption>
    </figure>

      </div>

  <div class="project-content e-content" itemprop="articleBody">
    <p>Plasticity is essential component in many biological neural networks, however many state of the art deep learning methods do not incorporate plasticity. Taking inspiration from the main mechanism of learning in biological brains: <em>synaptic plasticity</em>, carefully tuned by evolution to produce efficient lifelong learning, me along with my friend <a href="https://udion.github.io">Uddeshya</a> explored how could plasticity be infused in Deep and Convolutional Neural Networks to enhance the performance in terms of accuracy and memory footprint. We proposed a methodology on how to train such networks and study the effect of plasticity in different settings.</p>

<p>In the task of <em>pattern reconstruction</em>, we used <a href="https://en.wikipedia.org/wiki/Hebbian_theory">Hebbian plasticity</a> rule to start with. We first consider the problem of reconstructing the
given input to a desired output with minimum loss. Herein, each input is a vector of values in 
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mtext>−</mtext><mn>1</mn><mo separator="true">,</mo><mo>+</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{−1, +1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">+</span><span class="mord">1</span><span class="mclose">}</span></span></span></span>, of size <code class="highlighter-rouge">in_dim</code>. This input vector is degraded by randomly changing
some <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>−</mtext><mn>1</mn></mrow><annotation encoding="application/x-tex">−1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>s and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">+</span><span class="mord">1</span></span></span></span>s to 0. Now, this degraded vector is passed as an input to a fully-connected layer of neurons, each of which following the hebbian plasticity rule. We were able to recontruct <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>99.9</mn></mrow><annotation encoding="application/x-tex">99.9%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">9</span><span class="mord">9</span><span class="mord">.</span><span class="mord">9</span></span></span></span> of the input structure in ~900 epochs of training.</p>

<center>
<!--  -->


    <figure>
        <img src="/homepage/assets/images/Plasticity-based Learning in DNNs/plasticity1.png" />
        <figcaption>Performance of Plastic network in Pattern Reconstruction</figcaption>
    </figure>

</center>

<p>The results of this simple reconstruction task were encouraging, so we extended the analysis to public datasets like MNIST and FMNIST. To this end, we used an encoder-decoder based network with an additional fully-connected layer <em>after</em> encoder as well as decoder. Here too, the performance was better than that of non-plastic network. We were able to observe that our model performs significantly better for tasks of denoising. The future implications of this could be that we could include a plasticity-infused layer for denoising of corrupted data and subsequently deploy classification techniques, improving overall accuracy with a simpler model.</p>

<center>
<!--  -->


    <figure>
        <img src="/homepage/assets/images/Plasticity-based Learning in DNNs/plasticity2.png" />
        <figcaption>Performance of Plastic network in Pattern Reconstruction</figcaption>
    </figure>

</center>

<p>The inclusion of Plasticity in conventional neural network architecture promises good results in certain experiments. However, when we tried including plasticity in more common set of vision related task (denoising, classification), we failed to find much improvement over the baseline model <em>not</em> using plasticity. One of the drawback of using this framework of plasticity is that it fails to perform well when inputs are passed in batches and hence requires the input to be provided as one sample at a time, this inherently makes the training much slower even on GPUs since we can’t process multiple samples at a time.</p>


  </div><a class="u-url" href="/homepage/project/2018/11/30/plasticity-based-learning.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/homepage/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col one-half">
      <h2 class="footer-heading">Suyash Bagad</h2>
        <ul class="contact-list">
          <li class="p-name">Personal Webpage</li><li><a class="u-email" href="mailto:suyashbagad@iitb.ac.in">suyashbagad@iitb.ac.in</a></li></ul>
      </div>

      <div class="footer-col one-half">
        <em><small>Last updated on November 13, 2019</small></em>
        <small><br/></small>
        <em><small>© Suyash Bagad. Powered by Jekyll.
</small></em>
      </div>

      <div class="social-links"><ul class="social-media-list"><li><a href="https://github.com/suyash67" title="suyash67"><svg class="svg-icon grey"><use xlink:href="/homepage/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a href="https://www.linkedin.com/in/suyashbagad" title="suyashbagad"><svg class="svg-icon grey"><use xlink:href="/homepage/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a href="https://twitter.com/yet_to_come" title="yet_to_come"><svg class="svg-icon grey"><use xlink:href="/homepage/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>
    </div>

  </div>

</footer>
</body>

</html>
